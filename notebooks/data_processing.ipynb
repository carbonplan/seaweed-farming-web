{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911e4dac",
   "metadata": {},
   "source": [
    "<img width=\"50\" src=\"https://carbonplan-assets.s3.amazonaws.com/monogram/dark-small.png\" style=\"margin-left:0px;margin-top:20px\"/>\n",
    "\n",
    "# Macroalgae data prep\n",
    "\n",
    "_by Joe Hamman, October 7, 2021_\n",
    "\n",
    "This notebook processes multiple data layers related to the modeling of macroalgae for the purpose\n",
    "of carbon removal. The basic steps in this notebook are as follows:\n",
    "\n",
    "1. load and normalize input datasets\n",
    "2. build data pyamid for web map tool using `ndpyramid.pyramid_reproject`\n",
    "3. merge data layers into a single multi-dimensional array\n",
    "4. set storage encoding\n",
    "5. write data to cloud object store in Zarr format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84adc5f4",
   "metadata": {},
   "source": [
    "## imports and options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c38a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import fsspec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rioxarray  # noqa: F401\n",
    "import datatree\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from matplotlib import cm\n",
    "from showit import image\n",
    "\n",
    "from ndpyramid import pyramid_reproject\n",
    "from carbonplan_data.metadata import get_cf_global_attrs\n",
    "from carbonplan_data.utils import set_zarr_encoding\n",
    "from carbonplan_styles.mpl import set_theme\n",
    "\n",
    "import zarr\n",
    "\n",
    "\n",
    "# options for data processing\n",
    "pixels_per_tile = 128\n",
    "levels = 6\n",
    "mask_threshold = 0.001\n",
    "\n",
    "version = 0.9\n",
    "\n",
    "# options for diagnostic plots\n",
    "plot_diagnostics = False\n",
    "theme = set_theme()\n",
    "cmap = cm.get_cmap(\"cool_light\").copy()\n",
    "cmap.set_bad(\"0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5e4de",
   "metadata": {},
   "source": [
    "## helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grid_area(da):\n",
    "    \"\"\"\n",
    "    Compute the geographic area (in square meters) of every pixel in the data array provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : xarray.DataArray\n",
    "        DataArray with spatial coordinates longitude and latitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    areacella : xarray.DataArray\n",
    "        DataArray with grid cell areas in square meters\n",
    "    \"\"\"\n",
    "    R = 6.371e6\n",
    "    SQM_PER_HA = 10000\n",
    "    dϕ = np.radians((da[\"latitude\"][1] - da[\"latitude\"][0]).values)\n",
    "    dλ = np.radians((da[\"longitude\"][1] - da[\"longitude\"][0]).values)\n",
    "    dA = R ** 2 * np.abs(dϕ * dλ) * np.cos(np.radians(da[\"latitude\"]))\n",
    "    areacella = dA * xr.ones_like(da)\n",
    "\n",
    "    return areacella / SQM_PER_HA\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    ds = xr.Dataset()\n",
    "\n",
    "    print(\"loading d2p\")\n",
    "    with fsspec.open(\"gs://carbonplan-research/macroalgae/data/raw/d2port.nc\", mode=\"rb\") as f:\n",
    "        ds_raw = xr.open_dataset(f).load()\n",
    "        ds[\"d2p\"] = xr.DataArray(ds_raw[\"d2p\"].values, dims=(\"latitude\", \"longitude\"))\n",
    "\n",
    "    print(\"loading nvar + harv\")\n",
    "    for species in [\"Sargassum\", \"Eucheuma\", \"Macrocystis\", \"Porphyra\", \"Saccharina\"]:\n",
    "        with fsspec.open(\n",
    "            f\"gs://carbonplan-research/macroalgae/data/raw/mag0_output_std_lim_terms_{species}_f0.nc\",\n",
    "            mode=\"rb\",\n",
    "        ) as f:\n",
    "            ds_raw = xr.open_dataset(f, decode_cf=False).load()\n",
    "            ds_raw = xr.decode_cf(ds_raw.drop([\"time1\", \"time8\"]))\n",
    "            # ds[f'growth_{species.lower()}'] = ds_raw['Growth2']\n",
    "            ds[f\"harv_{species.lower()}\"] = ds_raw[\"harv\"]\n",
    "            ds[f\"nharv_{species.lower()}\"] = ds_raw[\"n_harv\"]\n",
    "\n",
    "    with fsspec.open(\n",
    "        \"gs://carbonplan-research/macroalgae/data/raw/Preferred_species_f0_v2.nc\",\n",
    "        mode=\"rb\",\n",
    "    ) as f:\n",
    "        ds_raw = xr.open_dataset(f).load()\n",
    "        #         ds[\"growth_preferred\"] = xr.DataArray(\n",
    "        #             ds_raw[\"Growth\"].values, dims=(\"latitude\", \"longitude\")\n",
    "        #         )\n",
    "        ds[\"species_preferred\"] = xr.DataArray(\n",
    "            ds_raw[\"index_H\"].values, dims=(\"latitude\", \"longitude\")\n",
    "        )\n",
    "        ds[\"harv_preferred\"] = xr.DataArray(\n",
    "            ds_raw[\"Harvest\"].values, dims=(\"latitude\", \"longitude\")\n",
    "        )\n",
    "        ds[\"nharv_preferred\"] = xr.DataArray(\n",
    "            ds_raw[\"nharv_H\"].values, dims=(\"latitude\", \"longitude\")\n",
    "        )\n",
    "\n",
    "    # hack to work around alignment issues\n",
    "    print(\"loading elevation\")\n",
    "    with fsspec.open(\"gs://carbonplan-research/macroalgae/data/raw/gebco_cwm.nc\", mode=\"rb\") as f:\n",
    "        ds[\"elevation\"] = xr.DataArray(\n",
    "            xr.open_dataset(f)[\"elevation\"].values, dims=(\"latitude\", \"longitude\")\n",
    "        )\n",
    "\n",
    "    print(\"loading d2sink\")\n",
    "    with fsspec.open(\n",
    "        \"gs://carbonplan-research/macroalgae/data/raw/d2sink_fseq_maps_v2.nc\", mode=\"rb\"\n",
    "    ) as f:\n",
    "        ds_raw = xr.open_dataset(f).load()\n",
    "        ds[\"d2sink\"] = xr.DataArray(ds_raw[\"d2sink\"].values, dims=(\"latitude\", \"longitude\"))\n",
    "        ds[\"fseq\"] = xr.DataArray(ds_raw[\"fseq_500years\"].values, dims=(\"latitude\", \"longitude\"))\n",
    "\n",
    "    print(\"loading wave height\")\n",
    "    with fsspec.open(\n",
    "        \"gs://carbonplan-research/macroalgae/data/raw/ecmwf_swh_2003_9km.nc\", mode=\"rb\"\n",
    "    ) as f:\n",
    "        with xr.open_dataset(f) as ds_temp:\n",
    "            # TODO: replace with proper calculation (waiting on email from UCI)\n",
    "            ds[\"wave_height\"] = xr.DataArray(\n",
    "                ds_temp[\"swh_mean\"].mean(\"time\").values, dims=(\"latitude\", \"longitude\")\n",
    "            )\n",
    "\n",
    "    print(\"loading mask\")\n",
    "    with fsspec.open(\n",
    "        \"gs://carbonplan-research/macroalgae/data/raw/mask_cbpm_2021_01_13.txt\", mode=\"r\"\n",
    "    ) as f:\n",
    "        df = pd.read_csv(f, sep=\" \", header=None)\n",
    "        ds[\"mask\"] = xr.DataArray(df.values, dims=(\"latitude\", \"longitude\"))\n",
    "        ds[\"mask\"] = ds[\"mask\"].astype(\"float64\")\n",
    "\n",
    "    # Skipping for now. Not 100% sure how to parse this one.\n",
    "    # with fsspec.open('gs://carbonplan-research/macroalgae/data/raw/area_twelfth_degree.txt', mode='r') as f:\n",
    "    #     df = pd.read_csv(f, sep=' ', header=None)\n",
    "    #     ds['area'] = xr.DataArray(df.values, dims=('latitude', 'longitude'))\n",
    "\n",
    "    ds[\"longitude\"] = ds[\"longitude\"].where(ds[\"longitude\"] < 180, ds[\"longitude\"] - 360)\n",
    "\n",
    "    ds[\"area\"] = compute_grid_area(ds[\"mask\"])\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def merge_layers(ds):\n",
    "    da = ds.to_array(dim=\"variable\").chunk(dict(x=pixels_per_tile, y=pixels_per_tile))\n",
    "    merged_ds = da.to_dataset(name=\"all_variables\")\n",
    "    return merged_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213a295",
   "metadata": {},
   "source": [
    "## load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_data()\n",
    "\n",
    "display(ds)\n",
    "# or ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9592b11",
   "metadata": {},
   "source": [
    "## diagnostic plots of \"raw\" data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_diagnostics:\n",
    "    for k, da in ds.items():\n",
    "        plt.figure(figsize=(14, 6), dpi=100)\n",
    "        print(k)\n",
    "        p = da.plot(\n",
    "            robust=True,\n",
    "            cmap=cmap,\n",
    "            subplot_kws=dict(projection=ccrs.PlateCarree()),\n",
    "            transform=ccrs.PlateCarree(),\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        p.axes.set_global()\n",
    "        p.axes.coastlines(color=\"#EBEBEC\", zorder=11)\n",
    "        p.axes.add_feature(cartopy.feature.LAND, facecolor=\"#1B1E23\", zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ab885",
   "metadata": {},
   "source": [
    "## create the data pyramid\n",
    "\n",
    "Here we create a multi-dimensional data pyramid. Data is masked based on a threshold set in the\n",
    "options section above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up per-variable resampling\n",
    "resampling = defaultdict(lambda: \"average\")\n",
    "resampling[\"species_preferred\"] = \"mode\"\n",
    "resampling[\"nharv_preferred\"] = \"mode\"\n",
    "resampling[\"nharv_sargassum\"] = \"mode\"\n",
    "resampling[\"nharv_eucheuma\"] = \"mode\"\n",
    "resampling[\"nharv_porphyra\"] = \"mode\"\n",
    "resampling[\"nharv_macrocystis\"] = \"mode\"\n",
    "resampling[\"nharv_saccharina\"] = \"mode\"\n",
    "resampling[\"fseq\"] = \"bilinear\"\n",
    "\n",
    "# set the nodata attribute before reprojecting\n",
    "for k, da in ds.data_vars.items():\n",
    "    if \"f\" in da.dtype.str:\n",
    "        ds[k] = da.rio.write_nodata(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e17658",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "pyramid = pyramid_reproject(ds, levels=levels, resampling=resampling)\n",
    "for child in pyramid.children:\n",
    "    child.ds = child.ds.where(child.ds[\"mask\"] > mask_threshold)\n",
    "    child.ds = child.ds[list(ds.data_vars)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff4242",
   "metadata": {},
   "source": [
    "## diagnostic plots of \"reprojected\" data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_diagnostics:\n",
    "\n",
    "    var_names = [\"harv_preferred\", \"nharv_preferred\", \"elevation\", \"mask\"]\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        4,\n",
    "        3,\n",
    "        figsize=(20, 20),\n",
    "        dpi=300,\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        subplot_kw=dict(projection=ccrs.Mercator.GOOGLE),\n",
    "    )\n",
    "\n",
    "    for i, level in enumerate([0, 2, 4]):\n",
    "        for j, (k, da) in enumerate(pyramid[f\"{level}\"].ds[var_names].items()):\n",
    "            ax = axes[j, i]\n",
    "            print(k)\n",
    "            p = da.plot(ax=ax, robust=True, cmap=cmap, transform=ccrs.Mercator.GOOGLE)\n",
    "            ax.set_global()\n",
    "            ax.coastlines(color=\"#EBEBEC\", zorder=11)\n",
    "            ax.add_feature(cartopy.feature.LAND, facecolor=\"#1B1E23\", zorder=10)\n",
    "            ax.set_title(f\"level: {level}\")\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0580edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if plot_diagnostics:\n",
    "#     fig, axes = plt.subplots(\n",
    "#         4,\n",
    "#         3,\n",
    "#         figsize=(20, 20),\n",
    "#         dpi=300,\n",
    "#         sharex=True,\n",
    "#         sharey=True,\n",
    "#         subplot_kw=dict(projection=ccrs.Mercator.GOOGLE),\n",
    "#     )\n",
    "\n",
    "#     j = 0\n",
    "\n",
    "#     for _j, (k, da) in enumerate(pyramid[f\"{level}\"].ds.items()):\n",
    "#         if k == \"harv_sargassum\" or k == \"harv_preferred\":\n",
    "#             for i, level in enumerate([0, 2, 4]):\n",
    "#                 ax = axes[j, i]\n",
    "#                 p = da.plot(ax=ax, robust=True, cmap=cmap, transform=ccrs.Mercator.GOOGLE)\n",
    "#                 ax.set_global()\n",
    "#                 ax.coastlines(color=\"#EBEBEC\", zorder=11)\n",
    "#                 ax.add_feature(cartopy.feature.LAND, facecolor=\"#1B1E23\", zorder=10)\n",
    "#                 ax.set_title(f\"level: {level}\")\n",
    "#             j += 1\n",
    "\n",
    "#     fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b120b",
   "metadata": {},
   "source": [
    "## merge data layers into a single array\n",
    "\n",
    "This step also sets the final encoding attributes for the output dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pyramid = datatree.DataTree()\n",
    "merged_pyramid.ds = xr.Dataset(attrs=get_cf_global_attrs(version=f\"{version}\"))\n",
    "\n",
    "for child in pyramid.children:\n",
    "    ds = merge_layers(child.ds)\n",
    "    merged_pyramid[child.name] = set_zarr_encoding(\n",
    "        ds, codec_config={\"id\": \"zlib\", \"level\": 1}, float_dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "merged_pyramid.ds.attrs[\"multiscales\"] = pyramid.ds.attrs[\"multiscales\"]\n",
    "display(merged_pyramid[\"1\"].ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe585fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pyramid.to_zarr(\n",
    "    f\"gs://carbonplan-research/macroalgae/data/processed/zarr-pyramid-{version}/\",\n",
    "    mode=\"w\",\n",
    "    consolidated=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
